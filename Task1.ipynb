{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "596ead62-95be-4dae-86da-bc894a0a4e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg     0       1      0  \n",
       "3  uZetl9T0NcROGOyFfughhg     1       2      0  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "df = pd.read_csv(\"yelp.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a087b94-72f8-48c1-943c-28767cdab289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We got here around midnight last Friday... the...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brought a friend from Louisiana here.  She say...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Every friday, my dad and I eat here. We order ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My husband and I were really, really disappoin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Love this place!  Was in phoenix 3 weeks for w...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars\n",
       "0  We got here around midnight last Friday... the...      4\n",
       "1  Brought a friend from Louisiana here.  She say...      5\n",
       "2  Every friday, my dad and I eat here. We order ...      3\n",
       "3  My husband and I were really, really disappoin...      1\n",
       "4  Love this place!  Was in phoenix 3 weeks for w...      5"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = df.sample(n=20, random_state=42).reset_index(drop=True)\n",
    "sample_df[['text', 'stars']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91f3ad46-9196-400d-b652-9e7521227fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=\"Your key",\n",
    ")\n",
    "\n",
    "def call_llm(prompt: str) -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/llama-3-8b-instruct\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a26feb19-050f-412a-855a-89e93bdd3a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt_v1(review_text: str) -> str:\n",
    "    return f\"\"\"\n",
    "You are a sentiment analysis assistant.\n",
    "\n",
    "Read the following Yelp review and decide how many stars (1 to 5) the user would likely give.\n",
    "\n",
    "Return ONLY a JSON object in this exact format:\n",
    "{{\n",
    "  \"predicted_stars\": <number from 1 to 5>,\n",
    "  \"explanation\": \"brief explanation here\"\n",
    "}}\n",
    "\n",
    "Review:\n",
    "\\\"\\\"\\\"{review_text}\\\"\\\"\\\"\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fdc8d326-2e6a-4c90-bd67-48c5054f439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt_v2(review_text: str) -> str:\n",
    "    return f\"\"\"\n",
    "You are an assistant that predicts Yelp star ratings.\n",
    "\n",
    "Use this scale:\n",
    "1 = very negative, angry, strong complaints\n",
    "2 = mostly negative, several issues\n",
    "3 = mixed/neutral, both positives and negatives\n",
    "4 = mostly positive, small issues only\n",
    "5 = very positive, highly satisfied, strongly recommended\n",
    "\n",
    "Read the review and decide the most appropriate rating from 1 to 5.\n",
    "\n",
    "Return ONLY valid JSON with no extra text:\n",
    "{{\n",
    "  \"predicted_stars\": <integer 1-5>,\n",
    "  \"explanation\": \"Brief one-sentence justification.\"\n",
    "}}\n",
    "\n",
    "Review:\n",
    "\\\"\\\"\\\"{review_text}\\\"\\\"\\\"\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc3b7f26-750a-4e4d-ac4a-6190467baa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt_v3(review_text: str) -> str:\n",
    "    return f\"\"\"\n",
    "You are predicting Yelp star ratings.\n",
    "\n",
    "Here are examples:\n",
    "\n",
    "Review: \"The food was cold and the service was rude. Never coming back.\"\n",
    "Response:\n",
    "{{\n",
    "  \"predicted_stars\": 1,\n",
    "  \"explanation\": \"Very negative review with bad food and rude service.\"\n",
    "}}\n",
    "\n",
    "Review: \"Food was okay, nothing special, but the price was reasonable.\"\n",
    "Response:\n",
    "{{\n",
    "  \"predicted_stars\": 3,\n",
    "  \"explanation\": \"Mixed feedback: average food, acceptable price.\"\n",
    "}}\n",
    "\n",
    "Review: \"Amazing service and delicious food. Highly recommend this place!\"\n",
    "Response:\n",
    "{{\n",
    "  \"predicted_stars\": 5,\n",
    "  \"explanation\": \"Strongly positive review with praise and recommendation.\"\n",
    "}}\n",
    "\n",
    "Now, follow the same style.\n",
    "\n",
    "Review: \\\"\\\"\\\"{review_text}\\\"\\\"\\\"\n",
    "\n",
    "Return ONLY JSON:\n",
    "{{\n",
    "  \"predicted_stars\": <integer 1-5>,\n",
    "  \"explanation\": \"Brief explanation.\"\n",
    "}}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ba64523a-a748-4ee3-bda5-13450fd72264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_prompt_version(build_prompt_fn, df, label_col=\"stars\"):\n",
    "    preds = []\n",
    "    json_valid_flags = []\n",
    "    \n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        review = row[\"text\"]\n",
    "        true_label = row[label_col]\n",
    "        \n",
    "        prompt = build_prompt_fn(review)\n",
    "        response = call_llm(prompt)      # <-- implement this\n",
    "        \n",
    "        pred_stars, explanation, is_valid = parse_json_response(response)\n",
    "        \n",
    "        json_valid_flags.append(is_valid)\n",
    "        if pred_stars is None:\n",
    "            # if invalid, you can choose to skip or assign a default value\n",
    "            preds.append(np.nan)\n",
    "        else:\n",
    "            preds.append(pred_stars)\n",
    "    \n",
    "    df_result = df.copy()\n",
    "    df_result[\"predicted_stars\"] = preds\n",
    "    df_result[\"json_valid\"] = json_valid_flags\n",
    "    \n",
    "    # Keep only rows with valid predictions for accuracy\n",
    "    valid_rows = df_result.dropna(subset=[\"predicted_stars\"])\n",
    "    accuracy = (valid_rows[\"predicted_stars\"] == valid_rows[label_col]).mean()\n",
    "    json_valid_rate = np.mean(json_valid_flags)\n",
    "    \n",
    "    return df_result, accuracy, json_valid_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8f41e5b7-095b-483b-bf59-15e1cfcc2cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def parse_json_response(response_text: str):\n",
    "    \"\"\"\n",
    "    Parses the JSON returned by the LLM.\n",
    "    Ensures:\n",
    "    - predicted_stars is an integer 1–5\n",
    "    - explanation is extracted\n",
    "    - returns (stars, explanation, is_valid)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = json.loads(response_text)\n",
    "\n",
    "        stars = data.get(\"predicted_stars\", None)\n",
    "        explanation = data.get(\"explanation\", \"\")\n",
    "\n",
    "        # Validate stars\n",
    "        if stars is None:\n",
    "            return None, None, False\n",
    "\n",
    "        stars = int(stars)\n",
    "        if stars < 1 or stars > 5:\n",
    "            return None, explanation, False\n",
    "\n",
    "        return stars, explanation, True\n",
    "\n",
    "    except Exception:\n",
    "        return None, None, False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "942aebc5-d62c-44f3-b85a-1faf4a127c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:42<00:00,  2.14s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:38<00:00,  1.90s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:33<00:00,  1.69s/it]\n"
     ]
    }
   ],
   "source": [
    "res_v1, acc_v1, json_v1 = evaluate_prompt_version(build_prompt_v1, sample_df)\n",
    "res_v2, acc_v2, json_v2 = evaluate_prompt_version(build_prompt_v2, sample_df)\n",
    "res_v3, acc_v3, json_v3 = evaluate_prompt_version(build_prompt_v3, sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7aff6cc-f791-4702-a0cc-e686d1c80ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1 - Basic Prompt\n",
      "  Accuracy:       0.6666666666666666\n",
      "  JSON valid %:   0.75\n",
      "\n",
      "V2 - Guidelines Prompt\n",
      "  Accuracy:       0.47058823529411764\n",
      "  JSON valid %:   0.85\n",
      "\n",
      "V3 - Few-shot Prompt\n",
      "  Accuracy:       0.5384615384615384\n",
      "  JSON valid %:   0.65\n"
     ]
    }
   ],
   "source": [
    "print(\"V1 - Basic Prompt\")\n",
    "print(\"  Accuracy:      \", acc_v1)\n",
    "print(\"  JSON valid %:  \", json_v1)\n",
    "\n",
    "print(\"\\nV2 - Guidelines Prompt\")\n",
    "print(\"  Accuracy:      \", acc_v2)\n",
    "print(\"  JSON valid %:  \", json_v2)\n",
    "\n",
    "print(\"\\nV3 - Few-shot Prompt\")\n",
    "print(\"  Accuracy:      \", acc_v3)\n",
    "print(\"  JSON valid %:  \", json_v3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a14a5949-a385-4a98-a1e5-f92d2c895835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_version</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>json_valid_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v1_basic</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v2_guidelines</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v3_few_shot</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prompt_version  accuracy  json_valid_rate\n",
       "0       v1_basic  0.666667             0.75\n",
       "1  v2_guidelines  0.470588             0.85\n",
       "2    v3_few_shot  0.538462             0.65"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison = pd.DataFrame({\n",
    "    \"prompt_version\": [\"v1_basic\", \"v2_guidelines\", \"v3_few_shot\"],\n",
    "    \"accuracy\": [acc_v1, acc_v2, acc_v3],\n",
    "    \"json_valid_rate\": [json_v1, json_v2, json_v3]\n",
    "})\n",
    "\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3604b338-b442-4551-bfc0-8b7af56a7fa0",
   "metadata": {},
   "source": [
    "The basic prompt (v1) gave the best accuracy. Since it was very simple, the model didn’t get confused and just focused on the actual review.\n",
    "\n",
    "The guidelines prompt (v2) had the lowest accuracy. Maybe the extra rules were too much and the model was getting pushed towards certain ratings.\n",
    "\n",
    "Few-shot (v3) came somewhere in between, not too good and not too bad.\n",
    "\n",
    "For JSON format, the results were opposite:\n",
    "\n",
    "v2 followed the JSON format most properly.\n",
    "\n",
    "v1 was okay-okay.\n",
    "\n",
    "v3 messed up JSON many times, maybe because the prompt became too long.\n",
    "\n",
    "In terms of reliability:\n",
    "\n",
    "v1 was more reliable for correct ratings.\n",
    "\n",
    "v2 was reliable for clean and proper JSON output.\n",
    "\n",
    "v3 was a bit unpredicatble overall.\n",
    "\n",
    "Overall, giving more instructions didn’t always help.\n",
    "The simple prompt worked best for accuracy, and the strict one worked best for JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31e6508-28cd-477e-8ad3-44906bc0b8f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13",
   "language": "python",
   "name": "py313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
